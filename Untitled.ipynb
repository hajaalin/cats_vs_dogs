{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc000d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 12:52:24.635654: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-21 12:52:24.678899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-21 12:52:25.292950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493749a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5c09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path(\"/scratch/tanhuanp/cats_vs_dogs\")\n",
    "datasetfile = DATADIR / \"kagglecatsanddogs_5340.zip\"\n",
    "assert datasetfile.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e759eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JPG images: 25000\n",
      "First 10 files: ['PetImages/Cat/', 'PetImages/Cat/0.jpg', 'PetImages/Cat/1.jpg', 'PetImages/Cat/10.jpg', 'PetImages/Cat/100.jpg', 'PetImages/Cat/1000.jpg', 'PetImages/Cat/10000.jpg', 'PetImages/Cat/10001.jpg', 'PetImages/Cat/10002.jpg', 'PetImages/Cat/10003.jpg']\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(datasetfile) as myzip:\n",
    "    filenames = myzip.namelist()\n",
    "    print('Total number of JPG images:', sum(['jpg' in f for f in filenames]))\n",
    "    print('First 10 files:', filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a815d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def str_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_example(image, filename, classname, classidx):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"filename\": str_feature(filename),\n",
    "        \"classname\": str_feature(classname),\n",
    "        \"classidx\": int64_feature(classidx),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHARDS = 10\n",
    "STORE_DECODED_IMAGES = True\n",
    "\n",
    "myzip = ZipFile(datasetfile)\n",
    "classindices = {}\n",
    "shards = np.array_split(myzip.infolist(), N_SHARDS)\n",
    "\n",
    "for i, shard in enumerate(shards):\n",
    "    tfrecfilename = \"images_{:03d}.tfrec\".format(i)\n",
    "    with tf.io.TFRecordWriter(str(DATADIR / tfrecfilename)) as writer:\n",
    "        n_images = 0\n",
    "        n_not_jfif = 0\n",
    "        for member in shard:\n",
    "            if member.filename.endswith(\".jpg\"):\n",
    "                #print(myzip.extract(member))\n",
    "                imagedata = myzip.read(member)\n",
    "                #print(imagedata[:10])\n",
    "                is_jfif = b\"JFIF\" in imagedata[:10]\n",
    "                \n",
    "                if is_jfif and STORE_DECODED_IMAGES:\n",
    "                    # there are corrupt images\n",
    "                    try:\n",
    "                        imagedata = tf.image.decode_image(imagedata)\n",
    "                        imagedata = tf.image.resize(imagedata, [256, 256])\n",
    "                        imagedata = tf.cast(imagedata, tf.uint8)\n",
    "                        if tf.shape(imagedata).numpy()[2] != 3:\n",
    "                            print(\"  skipping {} with {} channels\"\n",
    "                                  .format(member.filename, tf.shape(imagedata).numpy()[2]))\n",
    "                            continue\n",
    "                        imagedata = tf.io.serialize_tensor(imagedata).numpy()\n",
    "                    except Exception as exp:\n",
    "                        print(myzip.extract(member))\n",
    "                        print(exp)\n",
    "                n_images += 1\n",
    "                classname = re.findall(\"^.*PetImages/(.*)/\\d+.jpg$\", member.filename)[0]\n",
    "                if not (classname in classindices):\n",
    "                    classindices[classname] = len(classindices)\n",
    "\n",
    "                if is_jfif:\n",
    "                    example = create_example(imagedata, member.filename,\n",
    "                                             classname, classindices[classname])\n",
    "                    writer.write(example.SerializeToString())\n",
    "                else:\n",
    "                    n_not_jfif = n_not_jfif + 1\n",
    "        print(\"Wrote {} records in {} (shard {}, n_not_jfif {})\".format(n_images, tfrecfilename, i, n_not_jfif))\n",
    "myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aeeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_DECODED_IMAGES = True\n",
    "EXAMPLES_PER_FILE = 1000\n",
    "\n",
    "myzip = ZipFile(datasetfile)\n",
    "classindices = {}\n",
    "\n",
    "n_images = 0\n",
    "n_test = 0\n",
    "n_train = 0\n",
    "n_val = 0\n",
    "n_not_jfif = 0\n",
    "n_decode_errors = 0\n",
    "\n",
    "infolist = myzip.infolist()\n",
    "random.shuffle(infolist)\n",
    "for member in infolist:\n",
    "    print(member.filename)\n",
    "    if not member.filename.endswith(\".jpg\"):\n",
    "        continue\n",
    "        \n",
    "    imagedata = myzip.read(member)\n",
    "    #print(imagedata[:10])\n",
    "    is_jfif = b\"JFIF\" in imagedata[:10]\n",
    "    if not is_jfif:\n",
    "        n_not_jfif += 1\n",
    "        continue\n",
    "\n",
    "    decode_ok = False\n",
    "    if STORE_DECODED_IMAGES:\n",
    "        # there are corrupt images\n",
    "        try:\n",
    "            imagedata = tf.image.decode_image(imagedata)\n",
    "            imagedata = tf.image.resize(imagedata, [256, 256])\n",
    "            #print(imagedata.shape)\n",
    "            #break\n",
    "            imagedata = tf.cast(imagedata, tf.uint8)\n",
    "            if tf.shape(imagedata).numpy()[2] != 3:\n",
    "                raise ValueError(\"  skipping {} with {} channels\"\n",
    "                      .format(member.filename, tf.shape(imagedata).numpy()[2]))\n",
    "            imagedata = tf.io.serialize_tensor(imagedata).numpy()\n",
    "            decode_ok = True\n",
    "        except Exception as exp:\n",
    "            n_decode_errors += 1\n",
    "            print(myzip.extract(member))\n",
    "            print(exp)\n",
    "            \n",
    "    if not decode_ok:\n",
    "        continue\n",
    "        \n",
    "    n_images += 1\n",
    "\n",
    "    classname = re.findall(\"^.*PetImages/(.*)/\\d+.jpg$\", member.filename)[0]\n",
    "    if not (classname in classindices):\n",
    "        classindices[classname] = len(classindices)\n",
    "\n",
    "    example = create_example(imagedata, member.filename, \n",
    "                             classname, classindices[classname])\n",
    "\n",
    "    # 70/20/10% split for train/val/test datasets\n",
    "    # https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets\n",
    "    #test_dataset = dataset.enumerate().filter(lambda x,y: x%10==7).map(lambda x,y: y) \n",
    "    #val_dataset = dataset.enumerate().filter(lambda x,y: x%10>7).map(lambda x,y: y) \n",
    "    #train_dataset = dataset.enumerate().filter(lambda x,y: x%10<7).map(lambda x,y: y)\n",
    "    \n",
    "    if n_images % 10 < 7:\n",
    "        tfrecfilename = \"images_train_{:03d}.tfrec\".format(n_train // EXAMPLES_PER_FILE)\n",
    "        n_train += 1\n",
    "    if n_images % 10 > 7:\n",
    "        tfrecfilename = \"images_val_{:03d}.tfrec\".format(n_val // EXAMPLES_PER_FILE)\n",
    "        n_val += 1\n",
    "    if n_images % 10 == 7:\n",
    "        tfrecfilename = \"images_test_{:03d}.tfrec\".format(n_val // EXAMPLES_PER_FILE)\n",
    "        n_test += 1\n",
    "    \n",
    "    with tf.io.TFRecordWriter(str(DATADIR / tfrecfilename)) as writer:\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    print(\"n_train={}, n_val={}, n_test={}\".format(n_train, n_val, n_test))\n",
    "    \n",
    "myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=12345\n",
    "n=100\n",
    "print(l%n)\n",
    "print(n-l%n)\n",
    "print(l//n+1)\n",
    "print(l//n)\n",
    "(l%n)*(l//n+1) + (n-l%n)*(l//n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d7e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 12:54:18.576011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train=16231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_val=4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_test=2331\n"
     ]
    }
   ],
   "source": [
    "STORE_DECODED_IMAGES = True\n",
    "EXAMPLES_PER_FILE = 1000\n",
    "\n",
    "myzip = ZipFile(datasetfile)\n",
    "\n",
    "infolist = [info for info in myzip.infolist() if info.filename.endswith('.jpg')]\n",
    "random.shuffle(infolist)\n",
    "\n",
    "list_train = []\n",
    "list_val   = []\n",
    "list_test  = []\n",
    "\n",
    "i = 0\n",
    "for i, info in enumerate(infolist):\n",
    "    if i % 10 < 7:\n",
    "        list_train.append(info)\n",
    "    if i % 10 > 7:\n",
    "        list_val.append(info)\n",
    "    if i % 10 == 7:\n",
    "        list_test.append(info)\n",
    "\n",
    "\n",
    "classindices = {}\n",
    "\n",
    "n_images = 0\n",
    "n_test = 0\n",
    "n_train = 0\n",
    "n_val = 0\n",
    "n_not_jfif = 0\n",
    "n_decode_errors = 0\n",
    "\n",
    "def decode_image(imagedata):\n",
    "    imagedata = tf.image.decode_image(imagedata)\n",
    "    imagedata = tf.image.resize(imagedata, [256, 256])\n",
    "    #print(imagedata.shape)\n",
    "    #break\n",
    "    imagedata = tf.cast(imagedata, tf.uint8)\n",
    "    if tf.shape(imagedata).numpy()[2] != 3:\n",
    "        raise ValueError(\"  skipping {} with {} channels\"\n",
    "              .format(member.filename, tf.shape(imagedata).numpy()[2]))\n",
    "    imagedata = tf.io.serialize_tensor(imagedata).numpy()\n",
    "\n",
    "def create_tfrec_files(myzip, infolist, dataset_label):\n",
    "    n_shards = len(infolist) // EXAMPLES_PER_FILE\n",
    "    \n",
    "    n_images = 0\n",
    "    shards = np.array_split(infolist, n_shards)\n",
    "    for i, shard in enumerate(shards):\n",
    "        tfrecfilename = \"images_{}_{:03d}.tfrec\".format(dataset_label, i)\n",
    "        with tf.io.TFRecordWriter(str(DATADIR / tfrecfilename)) as writer:\n",
    "            n_not_jfif = 0\n",
    "            for member in shard:\n",
    "                #print(member.filename)\n",
    "        \n",
    "                imagedata = myzip.read(member)\n",
    "                #print(imagedata[:10])\n",
    "                is_jfif = b\"JFIF\" in imagedata[:10]\n",
    "                if not is_jfif:\n",
    "                    n_not_jfif += 1\n",
    "                    continue\n",
    "\n",
    "                decode_ok = False\n",
    "                if STORE_DECODED_IMAGES:\n",
    "                    # there are corrupt images\n",
    "                    try:\n",
    "                        imagedata = tf.image.decode_image(imagedata)\n",
    "                        imagedata = tf.image.resize(imagedata, [256, 256])\n",
    "                        #print(imagedata.shape)\n",
    "                        #break\n",
    "                        imagedata = tf.cast(imagedata, tf.uint8)\n",
    "                        if tf.shape(imagedata).numpy()[2] != 3:\n",
    "                            raise ValueError(\"  skipping {} with {} channels\"\n",
    "                                  .format(member.filename, tf.shape(imagedata).numpy()[2]))\n",
    "                        imagedata = tf.io.serialize_tensor(imagedata).numpy()\n",
    "                        decode_ok = True\n",
    "                    except Exception as exp:\n",
    "                        pass\n",
    "                        #print(myzip.extract(member))\n",
    "                        #print(exp)\n",
    "\n",
    "                if not decode_ok:\n",
    "                    continue\n",
    "        \n",
    "                n_images += 1\n",
    "\n",
    "                classname = re.findall(\"^.*PetImages/(.*)/\\d+.jpg$\", member.filename)[0]\n",
    "                if not (classname in classindices):\n",
    "                    classindices[classname] = len(classindices)\n",
    "\n",
    "                example = create_example(imagedata, member.filename, \n",
    "                                         classname, classindices[classname])\n",
    "\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "    print(\"n_{}={}\".format(dataset_label, n_images))\n",
    "\n",
    "\n",
    "datasets = {\"train\":list_train, \"val\":list_val, \"test\":list_test}\n",
    "for key in datasets.keys():\n",
    "    create_tfrec_files(myzip, datasets[key], key)\n",
    "\n",
    "\n",
    "myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b90e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500\n",
      "5000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(len(list_train))\n",
    "print(len(list_val))\n",
    "print(len(list_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_train / n_images)\n",
    "print(n_val / n_images)\n",
    "print(n_test / n_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    if STORE_DECODED_IMAGES:\n",
    "        return tf.io.parse_tensor(image, tf.uint8)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    return tf.cast(image, tf.uint8)\n",
    "\n",
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"filename\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"classname\": tf.io.FixedLenFeature((), tf.string),\n",
    "    \"classidx\": tf.io.FixedLenFeature((), tf.int64)}\n",
    "\n",
    "def load_image(example_proto):\n",
    "    ex = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return (preprocess_image(ex[\"image\"]), ex[\"classidx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrec_filenames = [str(DATADIR)+\"/images_{:03d}.tfrec\".format(i)\n",
    "                   for i in range(N_SHARDS)]\n",
    "random.shuffle(tfrec_filenames)\n",
    "\n",
    "full_dataset = tf.data.TFRecordDataset(tfrec_filenames)\n",
    "full_dataset = full_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Determine the size of your dataset\n",
    "# You can use the `reduce` method to count the number of elements in the dataset\n",
    "#dataset_size = dataset.reduce(tf.constant(0, dtype=tf.int64), lambda x, _: x + 1).numpy()\n",
    "\n",
    "# Calculate the number of elements in the dataset\n",
    "#dataset_size = 0\n",
    "#for _ in dataset:\n",
    "#    dataset_size += 1\n",
    "\n",
    "train_dataset, test_dataset = tf.keras.utils.split_dataset(full_dataset, left_size=0.8)\n",
    "\n",
    "# Define the split ratio\n",
    "#train_ratio = 0.8\n",
    "#train_size = int(dataset_size * train_ratio)\n",
    "#test_size = dataset_size - train_size\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#train_dataset = dataset.take(train_size)\n",
    "#test_dataset = dataset.skip(train_size)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(128).batch(batch_size, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.batch(batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70953b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = train_dataset.take(1).cardinality()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.cardinality().dtype\n",
    "#train_filenames\n",
    "#classindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef92579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(13,13))\n",
    "classnames = list(classindices.keys())\n",
    "for batch, labelidx in train_dataset.take(1):\n",
    "    print(batch.get_shape())\n",
    "    print(labelidx)\n",
    "    for i in range(16):    \n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(batch[i])\n",
    "        lidx = labelidx[i].numpy()\n",
    "        plt.title(\"{} ({})\".format(classnames[lidx], lidx))\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.suptitle('Some images from the Kaggle Cat vs. Dog dataset', fontsize=16, y=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43170f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
